{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T18:38:04.159743Z",
     "start_time": "2023-08-09T18:38:04.154507Z"
    },
    "collapsed": true
   },
   "source": [
    "\n",
    "# Exploring Hacker News Posts\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents <a name=\"begin\"></a>\n",
    "### 1. [Introduction](#introduction)\n",
    "* [Aim](#aim)\n",
    "* [Project Goal](#goal)\n",
    "\n",
    "### 2. [Opening Data](#open)\n",
    "\n",
    "\n",
    "### 3. [Removing Headers from a List of Lists](#remove)\n",
    "\n",
    "\n",
    "### 4. [Extracting Ask HN and Show HN Posts](#extract)\n",
    "\n",
    "\n",
    "### 5. [Data Analysis](#analysis)\n",
    "* [Calculating the Average Number of Comments for ask HN and Show HN](#average)\n",
    "* [Finding the number of Ask Posts and Comments by Hour Created](#hour)\n",
    "\n",
    "\n",
    "### 6. [ Conclusions](#conclusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "In this project, we'll work with a dataset of submissions to popular technology site Hacker News.\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of the Hacker News listings can get hundreds of thousands of visitors as a result.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aim** <a name=\"aim\"></a>\n",
    "\n",
    "The sole aim of this project is to help users identify the kind of stories that would receive more comments and on what exact hour of the day influences more comments when post are created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Project Goal** <a name=\"goal\"></a>\n",
    "\n",
    "The goal of this project is to analyze the Ask posts and Show posts to determine which receives the highest comments and on what exact hour of the day has the highest number of comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening Data <a name=\"open\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open(\"hacker_news.csv\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Headers from a List of Lists <a name=\"remove\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "# Displaying the header in the dataset\n",
    "headers = hn[0]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "# Removing the header from the dataset\n",
    "del(hn[0])\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts <a name=\"extract\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    Title = row[1] \n",
    "    title = Title.lower() #since startswith argument is case sensitive, we converted all characters to Lower case.\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of post in Ask_Post is 1744\n",
      "\n",
      "\n",
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The number of post in Ask_Post is 1162\n",
      "\n",
      "\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46']]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The number of post in Ask_Post is 17194\n",
      "\n",
      "\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']]\n"
     ]
    }
   ],
   "source": [
    "print('The number of post in Ask_Post is',len(ask_posts))\n",
    "print('\\n')\n",
    "print(ask_posts[:2])\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('The number of post in Ask_Post is',len(show_posts))\n",
    "print('\\n')\n",
    "print(show_posts[:2])\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('The number of post in Ask_Post is',len(other_posts))\n",
    "print('\\n')\n",
    "print(other_posts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis <a name=\"analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we want to determine which of the post recieves more comments on Harker News site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Average Number of Comments for ask HN and Show HN <a name=\"average\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.04\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average number of ask post comments\n",
    "total_ask_comments = 0\n",
    "for row in ask_posts:\n",
    "    comments = int(row[4])\n",
    "    total_ask_comments += comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(round(avg_ask_comments,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.32\n"
     ]
    }
   ],
   "source": [
    "# Calculating the average number of show post comments\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    comments = int(row[4])\n",
    "    total_show_comments += comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(round(avg_show_comments,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "From my findings, Ask HN has an average number of comment of 14.04, while Show HN has an average of 10.32.\n",
    "\n",
    "Hence, Ask HN receives more comments than Show HN.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the number of Ask Posts and Comments by Hour Created <a name=\"hour\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Ask posts are more likely to receive more comments, we will focus our remaining analysis just on these posts.\n",
    "\n",
    "Now, we will determine if ask posts created at a certain time are more likely to attract comments. Achieving this, we perform the following steps:\n",
    "\n",
    "1. Calculate the number of ask posts created in each hour of the day, along with the number of comments received.\n",
    "2. Calculate the average number of comments ask posts receive by hour created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**importing datetime module**\n",
    "\n",
    "Analysis is on ask_posts dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Calculate the number of ask posts created in each hour of the day, along with the number of comments received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['8/16/2016 9:55', 6], ['11/22/2015 13:43', 29], ['5/2/2016 10:14', 1], ['8/2/2016 14:20', 3], ['10/15/2015 16:38', 17], ['9/26/2015 23:23', 1], ['4/22/2016 12:24', 4], ['11/16/2015 9:22', 1], ['2/24/2016 17:57', 1], ['6/4/2016 17:17', 2]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4]) # Converting number of comments to integer\n",
    "    List = []\n",
    "    List.append(created_at)\n",
    "    List.append(num_comments)\n",
    "    result_list.append(List)\n",
    " \n",
    "    \n",
    "print(result_list[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Dictionary for Counts by Hour and Comments by Hour**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dictionary below contains the number of ask posts created during each hour of the day.\n",
      "\n",
      "\n",
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The dictionary below contains the corresponding number of comments created at each hour received.\n",
      "\n",
      "\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in result_list:\n",
    "    date_time_string = row[0]\n",
    "    date_time = dt.datetime.strptime(date_time_string, \"%m/%d/%Y %H:%M\")\n",
    "    hour = date_time.strftime(\"%H\")\n",
    "    comments = row[1]\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "        \n",
    "print('The dictionary below contains the number of ask posts created during each hour of the day.') \n",
    "print(\"\\n\")\n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(\"\\n\")\n",
    "print('The dictionary below contains the corresponding number of comments created at each hour received.')  \n",
    "print(\"\\n\")\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Calculating the Average Number of Comments for Ask HN Posts by Hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['09', 5.5777777777777775, 2],\n",
       " ['13', 14.741176470588234, 2],\n",
       " ['10', 13.440677966101696, 2],\n",
       " ['14', 13.233644859813085, 2],\n",
       " ['16', 16.796296296296298, 2],\n",
       " ['23', 7.985294117647059, 2],\n",
       " ['12', 9.41095890410959, 2],\n",
       " ['17', 11.46, 2],\n",
       " ['15', 38.5948275862069, 2],\n",
       " ['21', 16.009174311926607, 2],\n",
       " ['20', 21.525, 2],\n",
       " ['02', 23.810344827586206, 2],\n",
       " ['18', 13.20183486238532, 2],\n",
       " ['03', 7.796296296296297, 2],\n",
       " ['05', 10.08695652173913, 2],\n",
       " ['19', 10.8, 2],\n",
       " ['01', 11.383333333333333, 2],\n",
       " ['22', 6.746478873239437, 2],\n",
       " ['08', 10.25, 2],\n",
       " ['04', 7.170212765957447, 2],\n",
       " ['00', 8.127272727272727, 2],\n",
       " ['06', 9.022727272727273, 2],\n",
       " ['07', 7.852941176470588, 2],\n",
       " ['11', 11.051724137931034, 2]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour],2])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the result we need, but this format makes it difficult to identify the hours with the highest values.lets finish by sorting the list of lists and printing out the five highest values in a format that is easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting and Printing Values from a List of Lists** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since sorted() function can only work for the first element in a list of lists, and we want to sort for the average number of comments which is on the second element on every list. \n",
    "Hence, we proceed to swapping the first element with the second element on every List using a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.5777777777777775, '09'],\n",
       " [14.741176470588234, '13'],\n",
       " [13.440677966101696, '10'],\n",
       " [13.233644859813085, '14'],\n",
       " [16.796296296296298, '16'],\n",
       " [7.985294117647059, '23'],\n",
       " [9.41095890410959, '12'],\n",
       " [11.46, '17'],\n",
       " [38.5948275862069, '15'],\n",
       " [16.009174311926607, '21'],\n",
       " [21.525, '20'],\n",
       " [23.810344827586206, '02'],\n",
       " [13.20183486238532, '18'],\n",
       " [7.796296296296297, '03'],\n",
       " [10.08695652173913, '05'],\n",
       " [10.8, '19'],\n",
       " [11.383333333333333, '01'],\n",
       " [6.746478873239437, '22'],\n",
       " [10.25, '08'],\n",
       " [7.170212765957447, '04'],\n",
       " [8.127272727272727, '00'],\n",
       " [9.022727272727273, '06'],\n",
       " [7.852941176470588, '07'],\n",
       " [11.051724137931034, '11']]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new avg_by_hour list with swapped columns. \n",
    "\n",
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    first = row[0]\n",
    "    second = row[1]\n",
    "    swap_avg_by_hour.append([second,first])\n",
    "\n",
    "swap_avg_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "\n",
      "\n",
      "15:00: 38.59 average comments per post.\n",
      "02:00: 23.81 average comments per post.\n",
      "20:00: 21.52 average comments per post.\n",
      "16:00: 16.80 average comments per post.\n",
      "21:00: 16.01 average comments per post.\n"
     ]
    }
   ],
   "source": [
    "# Using the sorted() function to sort swap_avg_by_hour in descending function\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour,reverse=True)\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "print('\\n')\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = row[1]\n",
    "    avg_comment = row[0]\n",
    "    \n",
    "    date = dt.datetime.strptime(hour,\"%H\")\n",
    "    time = date.strftime(\"%H:%M\")\n",
    "    \n",
    "    template = \"{}: {:.2f} average comments per post.\".format(time,avg_comment)\n",
    "    \n",
    "    print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis, we can conclude that Ask_HR News has more and the highest comments when posted around 15:00 (3pm). Following that, more comments are likely to be received if Ask_HR News are posted in the morning as early as 2:00 (2am), and in the evening around 16:00 (4pm), 20:00 (8pm) and 21:00 (9pm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"conclusion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are aimed at analyzing Ask posts and Show posts to determine which receives the highest comments and on what exact hour of the day has the highest number of comments.\n",
    "\n",
    "Based on our analysis, Ask posts have more comments than Show post. And moving further, we were able to deduce that Ask posts receive more comments if posted in the midday towards evening around 3:00pm–4:00pm, and early hour of the day around 2:00am.\n",
    "\n",
    "Hence, to maximize the amount of comments a post receives, I would recommend Ask_HR news to be posted between in the morning by 2:00am and in the evening between 3:00pm–4:00pm.\n",
    "\n",
    "However, it should be noted that the dataset used for this analysis excluded post without comments. To this effect, we would be more convinced that our results and conclusion are accurate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Table of Content](#begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
